---
title: "Human tumor samples"
output: html_notebook
---

The goal of this project is to analyze single cell data from a paper. We'll use two fresh human tumor samples (one from Jessa et. al., the other from this paper)

```{r, include=FALSE}
library(here)
library(Seurat)
library(tidyverse)
library(patchwork)
```

### Reading data

Fresh tumor sample: KK21-H-072

Human ETMR tumor C19MC amplified

Patient age: 36 months

Note: All of Jessa et. al. samples come from C19MC amplified-tumors as well

```{r, warning=FALSE}
path <- paste0(here::here(), "/de Faria/input/scRNA/")
# list.files(path)

h072.data <- Read10X(path)

h072 <- CreateSeuratObject(counts = h072.data, project = "scfreshtumor", min.cells = 3, min.features = 200)

h072.data[1:3,1:4]

```

### QC metrics

```{r, warning=FALSE}

# The [[ operator can add columns to object metadata. This is a great place to stash QC stats
h072[["percent.mt"]] <- PercentageFeatureSet(h072, pattern = "^MT-")

# Visualize QC metrics as a violin plot
#This is better
VlnPlot(h072, features = c("nFeature_RNA", "nCount_RNA", "percent.mt"), ncol = 3)

# FeatureScatter is typically used to visualize feature-feature relationships, but can be used
# for anything calculated by the object, i.e. columns in object metadata, PC scores etc.
#This plots are less usefull for filtering than the violin plots

plot1 <- FeatureScatter(h072, feature1 = "nCount_RNA", feature2 = "percent.mt")
plot2 <- FeatureScatter(h072, feature1 = "nCount_RNA", feature2 = "nFeature_RNA")

plot1 + plot2


```

### Filtering the data

```{r}
#The threshold is determined based on the plots. Usual mitochondrial threshold for humans is around 10%, but in this case I see there's a lot of cells over that, so I'll try with a 20% and see after clustering if i need to make it more strict

h072 <- subset(h072, subset = nFeature_RNA > 200 & nFeature_RNA < 2000 & percent.mt < 20)
```

### Normalizing the data

```{r}

#This global scaling method assumes there's an equal number of RNA molecules in all the cells. There's other ways to mormalize data without assuming this (https://genomebiology.biomedcentral.com/articles/10.1186/s13059-021-02584-9 and https://satijalab.org/seurat/articles/sctransform_vignette). This code shows the default settings used when the function is called:

# h072 <- NormalizeData(h072, normalization.method = "LogNormalize", scale.factor = 10000)

h072 <- NormalizeData(h072)


```

### Identifying highly variable features (feature selection)

```{r}
#The method used to identify features as highly variable is described hede: https://www.sciencedirect.com/science/article/pii/S0092867419305598?via%3Dihub

h072 <- FindVariableFeatures(h072, selection.method = "vst", nfeatures = 2000)

top10 <- head(VariableFeatures(h072), 10)

# A warning comes up because the
variance_plot <- LabelPoints(plot = VariableFeaturePlot(h072), points = top10, repel = TRUE, xnudge = 0, ynudge = 0)

variance_plot

# 
# h072[["RNA"]]$counts[setdiff(Features(h072), VariableFeatures(h072)),]

```

### Scaling the data

```{r}
#Only variable features are scaled by default

#Seriously, look into SCTransform()

all.genes <- rownames(h072)
h072 <- ScaleData(h072, features = all.genes)
```

### Linear dimensional reduction

```{r}

#You should explore different approaches to choose how many dimensions to use. You can explore the PCs and look for relevant sources of heterogeneity (can be used in conjuction with GSEA), or you can use the elbow plot or a heuristic??. In any case, err on the side of more dimensions and experiment.

h072 <- RunPCA(h072, features = VariableFeatures(object = h072), verbose = FALSE)

VizDimLoadings(h072, dims = 1:2, reduction = "pca")

DimPlot(h072, reduction = "pca") + NoLegend()

DimHeatmap(h072, dims = 1:15, cells = 500, balanced = TRUE)
DimHeatmap(h072, dims = 2, cells = 500, balanced = TRUE)

ElbowPlot(h072)
```

### Clustering the cells

```{r linear}
#Seurat uses a graph-based approach that embeds cells into a graph structure, drawing edges between cells with similar feature expression patterns in order to partition the graph into highly interconnected "quasi-cliques"/"communities"

#Edge weights defined by Jaccard distance (shared overlap in local neighborhood) with FindNeighbors() using the number of PCs that was decided in th eprevious step

h072 <- FindNeighbors(h072, dims = 1:15)

#To cluster the cells Seurat uses the Louvain algorithm by default or SLM (http://dx.doi.org/10.1088/1742-5468/2008/10/P10008) to iteratively group cells together by optimizing the standard modularity function
#FindClusters() does this procedure and includes a parameter that sets the "granularity" of the clusters (larger values means more clusters; for 3k cells 0.4-1.2 is usually good and the value increases for larger datasets)

h072 <- FindClusters(h072, resolution = 0.2)


#You can see the clusters with Idents()

# head(Idents(h072), 5)

```

```{r non_linear}
#UMAP and tSNE are used to place similar cells together in low-dimensional space. This means that cells that were grouped in the same clusters in the previous step should colocalize in these plots.

#CAUTION!!! These representations can't capture more global relationships between cells and should not be used as the sole basis for drawing biological conclusions

h072 <- RunUMAP(h072, dims = 1:15)  

DimPlot(h072, reduction = "umap", label = TRUE)


```

### Finding DE features (cluster biomarkers)

```{r, warning=FALSE}
#Seurat ids positive and negative markers of single clusters compared to all other cells. FindAllMarkers() automated the process for all clusters, but you can choose groups of clusters and compare them to each other or other cells (FindMarkers()).
#Pretty sure under the hood there's Wilcoxon and AUCROC (Seurat asked to install the presto package to make these operations faster (https://github.com/immunogenomics/presto))

#There's a lot of options for DE analysis (https://satijalab.org/seurat/articles/de_vignette)

h072.markers <- FindAllMarkers(h072, min.pct = 0.25, min.diff.pct = 0.25)

h072.markers <- h072.markers %>%
    group_by(cluster) %>%
    dplyr::filter(avg_log2FC > 1)

de_per_cluster <- setNames(sapply(seq(0,5), function(x) h072.markers %>% filter(cluster==x) %>% select(gene)), paste0("Cluster",seq(0,5))) 


VlnPlot(h072, features = de_per_cluster$Cluster0)

# you can plot raw counts as well
VlnPlot(h072, features = c("COL9A2", "GPC2"), slot = "counts", log = TRUE)

FeaturePlot(h072, features = sample(h072.markers$gene, 10))

h072.markers %>%
    group_by(cluster) %>%
    dplyr::filter(avg_log2FC > 1) %>%
    slice_head(n = 10) %>%
    ungroup() -> top10

DoHeatmap(h072, features = top10$gene) + NoLegend()
```
